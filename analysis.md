# Analysis

In this analysis, we examine how different attention heads in the BERT model 
focus on various parts of the sentence structure. Specifically, we identify 
how certain layers establish relationships between subjects, verbs, and locations.

## Layer 1, Head 1

In Layer 1, Head 1, there is strong attention on the subject ("cat") and the masked verb ("[MASK]").
This suggests that this attention head may be responsible for connecting subjects with their verbs.

Example Sentences:
The cat appeared above the wall.
The cat was above the wall.
The cat flew above the wall.

## Layer 10, Head 1

Layer 10, Head 1 shows high attention on the masked verb ("[MASK]") and the location ("wall").
This suggests that this attention head helps associate verbs with their locations.

Example Sentences:
The cat appeared above the wall.
The cat was above the wall.
The cat flew above the wall.

